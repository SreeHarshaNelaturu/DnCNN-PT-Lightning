{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DnCNN_lightning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPaBmm9Dd3/2dD2aQLkWuOy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SreeHarshaNelaturu/DnCNN-PT-Lightning/blob/master/DnCNN_lightning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAEkVr7oC0nM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch-lightning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjcFqsUdL2Fg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1kssD0dG5dJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://www2.eecs.berkeley.edu/Research/Projects/CS/vision/bsds/BSDS300-images.tgz\n",
        "!tar xvzf BSDS300-images.tgz\n",
        "!rm BSDS300-images.tgz"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbITP8YGrd3t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision as tv\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import time"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eFZw_Pchrqxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlTvpLIgC2L4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NoisyDataset(Dataset):\n",
        "  def __init__(self, in_path, mode='train', img_size=(180, 180), sigma=30):\n",
        "    super(NoisyDataset, self).__init__()\n",
        "\n",
        "    self.mode = mode #train or test\n",
        "    self.in_path = in_path # ./BSDS300/images\n",
        "    self.img_size = img_size # (180, 180)\n",
        "\n",
        "\n",
        "    self.img_dir = os.path.join(in_path, mode)\n",
        "    self.imgs = os.listdir(self.img_dir)\n",
        "    self.sigma = sigma\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.imgs)\n",
        "  \n",
        "  def __repr__(self):\n",
        "      return \"Dataset Parameters: mode={}, img_size={}, sigma={}\".format(self.mode, self.img_size, self.sigma)\n",
        "    \n",
        "  def __getitem__(self, idx):\n",
        "\n",
        "      img_path = os.path.join(self.img_dir, self.imgs[idx])\n",
        "      clean_img = Image.open(img_path).convert('RGB')\n",
        "      left = np.random.randint(clean_img.size[0] - self.img_size[0])\n",
        "      top = np.random.randint(clean_img.size[1] - self.img_size[1])\n",
        "      # .crop(left, upper, right, lower)\n",
        "      cropped_clean = clean_img.crop([left, top, left+self.img_size[0], top+self.img_size[1]])\n",
        "      transform = tv.transforms.Compose([tv.transforms.ToTensor(),\n",
        "                                        tv.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "  \n",
        "      \n",
        "      ground_truth = transform(cropped_clean)\n",
        "\n",
        "      noisy = ground_truth + 2 / 255 * self.sigma * torch.randn(ground_truth.shape)\n",
        "      \n",
        "      return noisy, ground_truth \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbIQuiqQIDtH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dataset_imshow(image, ax=plt):\n",
        "    image = image.to('cpu').numpy()\n",
        "    image = np.moveaxis(image, [0, 1, 2], [2, 0, 1])\n",
        "    image = (image + 1) / 2\n",
        "    image[image < 0] = 0\n",
        "    image[image > 1] = 1\n",
        "    h = ax.imshow(image)\n",
        "    ax.axis('off')\n",
        "    \n",
        "    return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YMUEsHdiuCJD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Start tensorboard.\n",
        "%reload_ext tensorboard\n",
        "%tensorboard --logdir lightning_logs/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6NLcDlOHj6b",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "outputId": "da1cf031-6385-4458-f88c-f8cce4140bc3"
      },
      "source": [
        "class DnCNN(pl.LightningModule):\n",
        "  def __init__(self):\n",
        "    super(DnCNN, self).__init__()\n",
        "    \n",
        "    self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, padding=1)\n",
        "    self.conv2 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding=1)\n",
        "    self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding=1)\n",
        "    self.conv4 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding=1)\n",
        "    self.conv5 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding=1)\n",
        "    self.conv6 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding=1)\n",
        "    self.conv7 = nn.Conv2d(in_channels = 64, out_channels = 64, kernel_size = 3, padding=1)\n",
        "    self.conv8 = nn.Conv2d(in_channels = 64, out_channels = 3, kernel_size = 3, padding=1)\n",
        "    \n",
        "    self.bn1 = nn.BatchNorm2d(64, 64)\n",
        "    self.bn2 = nn.BatchNorm2d(64, 64)\n",
        "    self.bn3 = nn.BatchNorm2d(64, 64)\n",
        "    self.bn4 = nn.BatchNorm2d(64, 64)\n",
        "    self.bn5 = nn.BatchNorm2d(64, 64)\n",
        "    self.bn6 = nn.BatchNorm2d(64, 64)\n",
        "\n",
        "    self.dataset_dir = \"./BSDS300/images/\"\n",
        "  \n",
        "  def forward(self, x):\n",
        "      in_data = F.relu(self.conv1(x))\n",
        "      in_data = F.relu(self.bn1(self.conv2(in_data)))\n",
        "      in_data = F.relu(self.bn2(self.conv3(in_data)))\n",
        "      in_data = F.relu(self.bn3(self.conv4(in_data)))\n",
        "      in_data = F.relu(self.bn4(self.conv5(in_data)))\n",
        "      in_data = F.relu(self.bn5(self.conv6(in_data)))\n",
        "      in_data = F.relu(self.bn6(self.conv7(in_data)))\n",
        "      residual = self.conv8(in_data)\n",
        "      \n",
        "      y = residual + x\n",
        "      \n",
        "      return y\n",
        "  \n",
        "  def train_dataloader(self):\n",
        "      return DataLoader(NoisyDataset(self.dataset_dir), batch_size=20)\n",
        "  \n",
        "  \n",
        "  def training_step(self, batch, batch_nb):\n",
        "    x, y = batch\n",
        "    out = self(x)\n",
        "    mse = nn.MSELoss()\n",
        "    loss = mse(y, out)\n",
        "\n",
        "    tensorboard_logs = {'train_loss': loss}\n",
        "    return {'loss' : loss, 'log' : tensorboard_logs}\n",
        "\n",
        "  def configure_optimizers(self):\n",
        "    return torch.optim.Adam(self.parameters(), lr=0.001)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f951274b37f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDnCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDnCNN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pl' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bisktJTGMkaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "denoising_model = DnCNN()\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(filepath='./checkpoints/',  \n",
        "    save_top_k=1,  \n",
        "    monitor='loss',\n",
        "    verbose=True)\n",
        "\n",
        "\n",
        "trainer = pl.Trainer(gpus=1, max_epochs=20, checkpoint_callback=checkpoint_callback)\n",
        "\n",
        "trainer.fit(denoising_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jQF-J_2mgHe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls ./checkpoints/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np2SLKxycM2S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pretrained_model = DnCNN.load_from_checkpoint(\"./checkpoints/epoch=29.ckpt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9jB0msYiAdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_set = NoisyDataset(\"./BSDS300/images\", mode='test', img_size=(320, 320))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v84FFSd7gwNs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad(): \n",
        "  out = pretrained_model(test_set[2][0].unsqueeze(0))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dv9LuC3YHcj_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, axes = plt.subplots(ncols=2)\n",
        "dataset_imshow(test_set[2][0], ax=axes[0])\n",
        "axes[0].set_title('Noisy')\n",
        "dataset_imshow(out[0], ax=axes[1])\n",
        "axes[1].set_title('Clean')\n",
        "print(f'image size is {out[0].shape}.')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}